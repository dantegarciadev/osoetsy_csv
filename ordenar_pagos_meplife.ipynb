{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tkinter import filedialog\n",
    "import tkinter as tk\n",
    "import customtkinter as ctk\n",
    "from customtkinter import filedialog\n",
    "import funciones\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "import re\n",
    "import glob\n",
    "from librerias import funciones2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### subir el archivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "carpeta = None\n",
    "while carpeta is None:\n",
    "    directorio = funciones.seleccionar_directorio()\n",
    "    print(directorio)\n",
    "    if directorio:\n",
    "        try:\n",
    "            archivos_txt = glob.glob(directorio + '/*.txt')\n",
    "            datos_combinados = pd.DataFrame()\n",
    "            for archivo_txt in archivos_txt:\n",
    "                nombre_columna='codigo'\n",
    "                df = pd.read_csv(archivo_txt, header=None, names=[nombre_columna])\n",
    "                nombre_archivo = archivo_txt.split(\"/\")[-1].split(\".\")[0] # Extraer el nombre del archivo sin la extensión\n",
    "                df['nombre_archivo']= nombre_archivo\n",
    "                datos_combinados = pd.concat([datos_combinados, df])\n",
    "                \n",
    "            print(datos_combinados.dtypes)\n",
    "            break\n",
    "        except UnicodeDecodeError:\n",
    "            print(\"Error de decodificación de caracteres. Intenta con otra codificación o archivo.\")\n",
    "    else:\n",
    "        print(\"Directorio incorrecto. Por favor, vuelva a cargarlo.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_combinados.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limpiar registros HFTRANSF etc-- sin datos relevantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_combinados['codigo'] = datos_combinados['codigo'].astype(str)\n",
    "borrar = ['HFTRANSF','TNNOM','TFTR']\n",
    "# armo una expresion regular para combinar todas las cadenas de la lista\n",
    "patron = '|'.join(borrar)\n",
    "print(patron)\n",
    "datos_combinados_limpio= datos_combinados[~datos_combinados['codigo'].str.contains(patron, regex = True)]\n",
    "datos_combinados_limpio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Subir los pagos de MEPLIFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "carpeta = None\n",
    "while carpeta is None:\n",
    "    directorio = funciones.seleccionar_directorio()\n",
    "    print(directorio)\n",
    "    if directorio:\n",
    "        try:\n",
    "            archivos_txt = glob.glob(directorio + '/*.txt')\n",
    "            pago_mep = pd.DataFrame()\n",
    "            for archivo_txt in archivos_txt:\n",
    "                nombre_columna='codigo'\n",
    "                df = pd.read_csv(archivo_txt, header=None, names=[nombre_columna])\n",
    "                nombre_archivo = archivo_txt.split(\"/\")[-1].split(\".\")[0] # Extraer el nombre del archivo sin la extensión\n",
    "                df['nombre_archivo']= nombre_archivo\n",
    "                pago_mep = pd.concat([pago_mep, df])\n",
    "                print(pago_mep)\n",
    "                \n",
    "            print(pago_mep)\n",
    "            break\n",
    "        except UnicodeDecodeError:\n",
    "            print(\"Error de decodificación de caracteres. Intenta con otra codificación o archivo.\")\n",
    "    else:\n",
    "        print(\"Directorio incorrecto. Por favor, vuelva a cargarlo.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### splitear en columnas pagos AFIP y MEPLIFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_combinados_limpio['ORGAN']=datos_combinados_limpio['codigo'].str.slice(0,4)\n",
    "datos_combinados_limpio['CODCONC'] = datos_combinados_limpio['codigo'].str.slice(4,7)\n",
    "datos_combinados_limpio['IMPORTE']= (datos_combinados_limpio['codigo'].str.slice(7, 22).astype(int)/100).round(2)\n",
    "datos_combinados_limpio['INDDBCR']= datos_combinados_limpio['codigo'].str.slice(22, 23)\n",
    "datos_combinados_limpio['FECPROC']= datos_combinados_limpio['codigo'].str.slice(23, 33)\n",
    "datos_combinados_limpio['FECREC']= pd.to_datetime(datos_combinados_limpio['codigo'].str.slice(33, 43))\n",
    "datos_combinados_limpio['CUITCONT']= datos_combinados_limpio['codigo'].str.slice(43, 54)\n",
    "datos_combinados_limpio['DNI_CONT']=datos_combinados_limpio['codigo'].str.slice(45, 53).astype('int64')\n",
    "datos_combinados_limpio['PERIODO']= datos_combinados_limpio['codigo'].str.slice(54, 58)\n",
    "datos_combinados_limpio['ID_TRANFER']= datos_combinados_limpio['codigo'].str.slice(58, 73)\n",
    "datos_combinados_limpio['CUITAPO']= datos_combinados_limpio['codigo'].str.slice(73, 84)\n",
    "datos_combinados_limpio['BANCO']= datos_combinados_limpio['codigo'].str.slice(84, 87)\n",
    "datos_combinados_limpio['CODSUC']= datos_combinados_limpio['codigo'].str.slice(87, 90)\n",
    "datos_combinados_limpio['ZONA']= datos_combinados_limpio['codigo'].str.slice(90, 92)\n",
    "datos_combinados_limpio['USOFUTURO']= datos_combinados_limpio['codigo'].str.slice(92, 94)\n",
    "datos_combinados_limpio['USOFUTURO1']= datos_combinados_limpio['codigo'].str.slice(94, 95)\n",
    "datos_combinados_limpio['USOFUTURO2']= datos_combinados_limpio['codigo'].str.slice(95, 96)\n",
    "datos_combinados_limpio['USOFUTUR3']= datos_combinados_limpio['codigo'].str.slice(96, 98)\n",
    "datos_combinados_limpio['TIPOPAGO']= datos_combinados_limpio['codigo'].str.slice(98, 99)\n",
    "datos_combinados_limpio['MARCAPR']= datos_combinados_limpio['codigo'].str.slice(99, 100)\n",
    "\n",
    "\n",
    "# ahora los pagos de meplife\n",
    "pago_mep['ORGAN']=pago_mep['codigo'].str.slice(0,4)\n",
    "pago_mep['CODCONC'] = pago_mep['codigo'].str.slice(4,7)\n",
    "pago_mep['IMPORTE']= (pago_mep['codigo'].str.slice(7, 22).astype(int)/100).round(2)\n",
    "pago_mep['INDDBCR']= pago_mep['codigo'].str.slice(22, 23)\n",
    "pago_mep['FECPROC']= pago_mep['codigo'].str.slice(23, 33)\n",
    "pago_mep['FECREC']= pd.to_datetime(pago_mep['codigo'].str.slice(33, 43))\n",
    "pago_mep['CUITCONT']= pago_mep['codigo'].str.slice(43, 54)\n",
    "pago_mep['DNI_CONT']=pago_mep['codigo'].str.slice(45, 53).astype('int64')\n",
    "pago_mep['PERIODO']= pago_mep['codigo'].str.slice(54, 58)\n",
    "pago_mep['ID_TRANFER']= pago_mep['codigo'].str.slice(58, 73)\n",
    "pago_mep['CUITAPO']= pago_mep['codigo'].str.slice(73, 84)\n",
    "pago_mep['BANCO']= pago_mep['codigo'].str.slice(84, 87)\n",
    "pago_mep['CODSUC']= pago_mep['codigo'].str.slice(87, 90)\n",
    "pago_mep['ZONA']= pago_mep['codigo'].str.slice(90, 92)\n",
    "pago_mep['USOFUTURO']= pago_mep['codigo'].str.slice(92, 94)\n",
    "pago_mep['USOFUTURO1']= pago_mep['codigo'].str.slice(94, 95)\n",
    "pago_mep['USOFUTURO2']= pago_mep['codigo'].str.slice(95, 96)\n",
    "pago_mep['USOFUTUR3']= pago_mep['codigo'].str.slice(96, 98)\n",
    "pago_mep['TIPOPAGO']= pago_mep['codigo'].str.slice(98, 99)\n",
    "pago_mep['MARCAPR']= pago_mep['codigo'].str.slice(99, 100)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ordenar y contar pagos por fechas los pagos AFIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(datos_combinados_limpio['IMPORTE'])\n",
    "#total = datos_combinados_limpio['IMPORTE'].sum().round(2)\n",
    "datos_combinados_fecha = datos_combinados_limpio[(datos_combinados_limpio['FECREC']>'2020-01-01') & (datos_combinados_limpio['FECREC']<'2020-12-30')]\n",
    "datos_combinados_fecha.sort_values(by=['FECREC'], ascending=True)\n",
    "#total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CRUZAR LOS DATAFRAMES VALIDACIONES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#verificamos que todos los registros enviados a meplife, se encuentran en los archivos de pagos de AFIP\n",
    "meplife_verificacion = pd.merge(pago_mep, datos_combinados_limpio, left_on='codigo', right_on='codigo', how='right', indicator=True)\n",
    "meplife_verificacion_final = meplife_verificacion[meplife_verificacion['_merge'] == 'right_only']\n",
    "meplife_verificacion_final.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### importar finales "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar los registros de meplife que coinicden\n",
    "no_enviados = meplife_verificacion[meplife_verificacion['_merge'] == 'right_only']\n",
    "no_enviados.drop(columns=['_merge'], inplace=True)\n",
    "\n",
    "#path = funciones.seleccionar_directorio()\n",
    "#no_enviados.to_excel(path + '/meplife_no_enviado.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Subir el excel con los CUITS / DNI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cargar primero el padron de sidefi\n",
    "archivo = None\n",
    "while True:\n",
    "    archivo = funciones.seleccionar_archivo()\n",
    "    print(archivo)\n",
    "    if archivo:\n",
    "        ruta_archivo = archivo.name\n",
    "        try:\n",
    "            dni_meplife = pd.read_excel(ruta_archivo)\n",
    "            #padron = pd.read_csv(archivo, sep=\";\", encoding=\"ISO-8859-1\")\n",
    "            print(dni_meplife)\n",
    "            break\n",
    "        except UnicodeDecodeError:\n",
    "            print(\"Error de decodificación de caracteres. Intenta con otra codificación o archivo.\")\n",
    "            continue\n",
    "    else:\n",
    "        print(\"Archivo incorrecto. Por favor, vuelva a cargarlo.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dni_meplife.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### obtener los pagos no enviados a meplife de servicio domestico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_enviados['DNI_CONT_y'] = no_enviados['DNI_CONT_y'].astype('int64')\n",
    "liquidacion_serv_dom = pd.merge(dni_meplife, no_enviados, how= 'inner', left_on='Nro_Doc', right_on='DNI_CONT_y', indicator=True )\n",
    "path = funciones.seleccionar_directorio()\n",
    "liquidacion_serv_dom.to_excel(path + '/liquidacionfinal.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### obetener los pagos enviados con los DNI presentados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pagos_enviados_mep = pd.merge(dni_meplife, pago_mep, left_on='Nro_Doc', right_on='DNI_CONT', how='inner', indicator=True)\n",
    "path = funciones.seleccionar_directorio()\n",
    "pagos_enviados_mep.to_excel(path + '/pagos_enviados.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pagos_enviados_mepv2 = pd.merge(dni_meplife, datos_combinados_limpio, left_on='Nro_Doc', right_on='DNI_CONT', how='inner', indicator=True)\n",
    "path = funciones.seleccionar_directorio()\n",
    "pagos_enviados_mepv2.to_excel(path + '/pagos_recibidos_total.xlsx')\n",
    "print(datos_combinados.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
