{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tkinter import filedialog\n",
    "import tkinter as tk\n",
    "import customtkinter as ctk\n",
    "from customtkinter import filedialog\n",
    "import funciones\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "import re\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unir TXT TIS SD EVP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directorio = None\n",
    "while directorio is None:\n",
    "    directorio = funciones.seleccionar_directorio()\n",
    "    print(directorio)\n",
    "    if directorio:\n",
    "        try:\n",
    "            pago_tis = pd.DataFrame() # Crear un dataframe vacío para almacenar los datos\n",
    "            for dirpath, dirnames, filenames in os.walk(directorio): # Recorrer los directorios y subdirectorios\n",
    "                archivos_txt = glob.glob(os.path.join(dirpath, \"*.txt\")) # Obtener los archivos txt en cada subdirectorio\n",
    "                for archivo_txt in archivos_txt: # Recorrer los archivos txt\n",
    "                    nombre_columna = \"codigo\"\n",
    "                    df = pd.read_csv(archivo_txt, header=None, names=[nombre_columna]) # Leer el archivo como un dataframe\n",
    "                    nombre_archivo = os.path.basename(archivo_txt) # Extraer el nombre del archivo con la extensión\n",
    "                    nombre_subcarpeta = os.path.basename(dirpath) # Extraer el nombre de la subcarpeta\n",
    "                    df[\"nombre_archivo\"] = os.path.join(nombre_subcarpeta, nombre_archivo) # Unir el nombre de la subcarpeta y el nombre del archivo\n",
    "                    pago_tis = pd.concat([pago_tis, df]) # Concatenar el dataframe con el dataframe final\n",
    "            if not pago_tis.empty: # Verificar si el dataframe final no está vacío\n",
    "                print(pago_tis.dtypes)\n",
    "                break # Salir del bucle si se han leído y concatenado archivos txt\n",
    "        except UnicodeDecodeError:\n",
    "            print(\"Error de decodificación de caracteres. Intenta con otra codificación o archivo.\")\n",
    "    else:\n",
    "        print(\"Directorio incorrecto. Por favor, vuelva a cargarlo.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pago_tis.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subir el periodo actualizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directorio = None\n",
    "while directorio is None:\n",
    "    directorio = funciones.seleccionar_directorio()\n",
    "    print(directorio)\n",
    "    if directorio:\n",
    "        try:\n",
    "            historico_tis = pd.DataFrame() # Crear un dataframe vacío para almacenar los datos\n",
    "            for dirpath, dirnames, filenames in os.walk(directorio): # Recorrer los directorios y subdirectorios\n",
    "                archivos_txt = glob.glob(os.path.join(dirpath, \"*.txt\")) # Obtener los archivos txt en cada subdirectorio\n",
    "                for archivo_txt in archivos_txt: # Recorrer los archivos txt\n",
    "                    nombre_columna = \"codigo\"\n",
    "                    df = pd.read_csv(archivo_txt, header=None, names=[nombre_columna]) # Leer el archivo como un dataframe\n",
    "                    nombre_archivo = os.path.basename(archivo_txt) # Extraer el nombre del archivo con la extensión\n",
    "                    nombre_subcarpeta = os.path.basename(dirpath) # Extraer el nombre de la subcarpeta\n",
    "                    df[\"nombre_archivo\"] = os.path.join(nombre_subcarpeta, nombre_archivo) # Unir el nombre de la subcarpeta y el nombre del archivo\n",
    "                    historico_tis = pd.concat([historico_tis, df]) # Concatenar el dataframe con el dataframe final\n",
    "            if not historico_tis.empty: # Verificar si el dataframe final no está vacío\n",
    "                print(historico_tis.dtypes)\n",
    "                break # Salir del bucle si se han leído y concatenado archivos txt\n",
    "        except UnicodeDecodeError:\n",
    "            print(\"Error de decodificación de caracteres. Intenta con otra codificación o archivo.\")\n",
    "    else:\n",
    "        print(\"Directorio incorrecto. Por favor, vuelva a cargarlo.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historico_tis.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### splitear en columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pago_tis['ORGAN']=pago_tis['codigo'].str.slice(0,4)\n",
    "pago_tis['CODCONC'] = pago_tis['codigo'].str.slice(4,7)\n",
    "pago_tis['IMPORTE']= (pago_tis['codigo'].str.slice(7, 22).astype(int)/100).round(2)\n",
    "pago_tis['INDDBCR']= pago_tis['codigo'].str.slice(22, 23)\n",
    "pago_tis['FECPROC']= pago_tis['codigo'].str.slice(23, 33)\n",
    "pago_tis['FECREC']= pago_tis['codigo'].str.slice(33, 43)\n",
    "pago_tis['CUITCONT']= pago_tis['codigo'].str.slice(43, 54)\n",
    "pago_tis['DNI_CONT']=pago_tis['codigo'].str.slice(45, 53)\n",
    "pago_tis['PERIODO']= pago_tis['codigo'].str.slice(54, 58)\n",
    "pago_tis['ID_TRANFER']= pago_tis['codigo'].str.slice(58, 73)\n",
    "pago_tis['CUITAPO']= pago_tis['codigo'].str.slice(73, 84)\n",
    "pago_tis['BANCO']= pago_tis['codigo'].str.slice(84, 87)\n",
    "pago_tis['CODSUC']= pago_tis['codigo'].str.slice(87, 90)\n",
    "pago_tis['ZONA']= pago_tis['codigo'].str.slice(90, 92)\n",
    "pago_tis['USOFUTURO']= pago_tis['codigo'].str.slice(92, 94)\n",
    "pago_tis['USOFUTURO1']= pago_tis['codigo'].str.slice(94, 95)\n",
    "pago_tis['USOFUTURO2']= pago_tis['codigo'].str.slice(95, 96)\n",
    "pago_tis['USOFUTURO3']= pago_tis['codigo'].str.slice(96, 98)\n",
    "pago_tis['TIPOPAGO']= pago_tis['codigo'].str.slice(98, 99)\n",
    "pago_tis['MARCAPR']= pago_tis['codigo'].str.slice(99, 100)\n",
    "\n",
    "## Lo mismo con el dataframe historico\n",
    "historico_tis['ORGAN']=historico_tis['codigo'].str.slice(0,4)\n",
    "historico_tis['CODCONC'] = historico_tis['codigo'].str.slice(4,7)\n",
    "historico_tis['IMPORTE']= (historico_tis['codigo'].str.slice(7, 22).astype(int)/100).round(2)\n",
    "historico_tis['INDDBCR']= historico_tis['codigo'].str.slice(22, 23)\n",
    "historico_tis['FECPROC']= historico_tis['codigo'].str.slice(23, 33)\n",
    "historico_tis['FECREC']= historico_tis['codigo'].str.slice(33, 43)\n",
    "historico_tis['CUITCONT']= historico_tis['codigo'].str.slice(43, 54)\n",
    "historico_tis['DNI_CONT']=historico_tis['codigo'].str.slice(45, 53)\n",
    "historico_tis['PERIODO']= historico_tis['codigo'].str.slice(54, 58)\n",
    "historico_tis['ID_TRANFER']= historico_tis['codigo'].str.slice(58, 73)\n",
    "historico_tis['CUITAPO']= historico_tis['codigo'].str.slice(73, 84)\n",
    "historico_tis['BANCO']= historico_tis['codigo'].str.slice(84, 87)\n",
    "historico_tis['CODSUC']= historico_tis['codigo'].str.slice(87, 90)\n",
    "historico_tis['ZONA']= historico_tis['codigo'].str.slice(90, 92)\n",
    "historico_tis['USOFUTURO']= historico_tis['codigo'].str.slice(92, 94)\n",
    "historico_tis['USOFUTURO1']= historico_tis['codigo'].str.slice(94, 95)\n",
    "historico_tis['USOFUTURO2']= historico_tis['codigo'].str.slice(95, 96)\n",
    "historico_tis['USOFUTURO3']= historico_tis['codigo'].str.slice(96, 98)\n",
    "historico_tis['TIPOPAGO']= historico_tis['codigo'].str.slice(98, 99)\n",
    "historico_tis['MARCAPR']= historico_tis['codigo'].str.slice(99, 100)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pago_tis['IMPORTE'].sum()\n",
    "historico_tis['IMPORTE'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge liquidaciones e historico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cruce_liquid= pd.merge(pago_tis, historico_tis, left_on='codigo', right_on='codigo', how='right', indicator=True)\n",
    "#cruce_liquid.to_csv(\"prueba.csv\", index=False, sep=';')\n",
    "liqui_no_enviada=cruce_liquid[cruce_liquid[\"_merge\"] == \"right_only\"]\n",
    "liqui_no_enviada.rename(columns={\"_merge\":\"cruce1\"}, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "cruce_liquid['IMPORTE']= (cruce_liquid['codigo'].str.slice(7, 22).astype(float)/100).round(2)\n",
    "cruce_liquid['FECPROC']= cruce_liquid['codigo'].str.slice(23, 33)\n",
    "cruce_liquid['FECREC']= cruce_liquid['codigo'].str.slice(33, 43)\n",
    "cruce_liquid['CUITCONT']= cruce_liquid['codigo'].str.slice(43, 54).astype('int64')\n",
    "cruce_liquid['DNI_CONT']=cruce_liquid['codigo'].str.slice(45, 53).astype(int)\n",
    "cruce_liquid['PERIODO']= cruce_liquid['codigo'].str.slice(54, 58)\n",
    "cruce_liquid['CUITAPO']= cruce_liquid['codigo'].str.slice(73, 84).astype('Int64')\n",
    "cruce_liquid.rename(columns={'_merge':'cruce1'},inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### formatear liquidacion limpia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liqui_no_enviada['ORGAN']=liqui_no_enviada['codigo'].str.slice(0,4)\n",
    "liqui_no_enviada['CODCONC'] = liqui_no_enviada['codigo'].str.slice(4,7)\n",
    "liqui_no_enviada['IMPORTE']= (liqui_no_enviada['codigo'].str.slice(7, 22).astype(float)/100).round(2)\n",
    "liqui_no_enviada['INDDBCR']= liqui_no_enviada['codigo'].str.slice(22, 23)\n",
    "liqui_no_enviada['FECPROC']= liqui_no_enviada['codigo'].str.slice(23, 33)\n",
    "liqui_no_enviada['FECREC']= liqui_no_enviada['codigo'].str.slice(33, 43)\n",
    "liqui_no_enviada['CUITCONT']= liqui_no_enviada['codigo'].str.slice(43, 54)\n",
    "liqui_no_enviada['DNI_CONT']=liqui_no_enviada['codigo'].str.slice(45, 53).astype(int)\n",
    "liqui_no_enviada['PERIODO']= liqui_no_enviada['codigo'].str.slice(54, 58)\n",
    "liqui_no_enviada['ID_TRANFER']= liqui_no_enviada['codigo'].str.slice(58, 73)\n",
    "liqui_no_enviada['CUITAPO']= liqui_no_enviada['codigo'].str.slice(73, 84)\n",
    "liqui_no_enviada['BANCO']= liqui_no_enviada['codigo'].str.slice(84, 87)\n",
    "liqui_no_enviada['CODSUC']= liqui_no_enviada['codigo'].str.slice(87, 90)\n",
    "liqui_no_enviada['ZONA']= liqui_no_enviada['codigo'].str.slice(90, 92)\n",
    "liqui_no_enviada['USOFUTURO']= liqui_no_enviada['codigo'].str.slice(92, 94)\n",
    "liqui_no_enviada['USOFUTURO1']= liqui_no_enviada['codigo'].str.slice(94, 95)\n",
    "liqui_no_enviada['USOFUTURO2']= liqui_no_enviada['codigo'].str.slice(95, 96)\n",
    "liqui_no_enviada['USOFUTURO3']= liqui_no_enviada['codigo'].str.slice(96, 98)\n",
    "liqui_no_enviada['TIPOPAGO']= liqui_no_enviada['codigo'].str.slice(98, 99)\n",
    "liqui_no_enviada['MARCAPR']= liqui_no_enviada['codigo'].str.slice(99, 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liqui_no_enviada['IMPORTE'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subir y limpiar padron SIDEFI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archivo = funciones.seleccionar_archivo()\n",
    "if archivo:\n",
    "    padron = pd.read_csv(archivo, sep=\";\", encoding=\"ISO-8859-1\")\n",
    "\n",
    "padron = padron[[\"Nro. OS\",\"Plan del Afiliado\", \"Nro. Documento\"]]\n",
    "padron[\"Nro. Documento\"] = padron[\"Nro. Documento\"].astype(int)\n",
    "padron.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "padron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cruzar padron sidefi con liquidaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "liq_convenio_merge = pd.merge(liqui_no_enviada, padron, left_on = \"DNI_CONT\", right_on=\"Nro. Documento\", how='left', indicator=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liq_convenio_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = filedialog.askdirectory()\n",
    "liq_convenio_merge.to_csv(save_path + '\\liq_2022_2023.csv' , sep=\t';' , index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "liq_convenio_final = liq_convenio_merge\n",
    "liq_convenio_final.drop_duplicates(subset='codigo', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "liq_convenio_final['CUITAPO']=liq_convenio_final['CUITAPO'].astype(np.int64)\n",
    "liq_convenio_final.rename(columns={\"_merge\":\"cruce2\"}, inplace = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cruce con el reporte de TIS, mediante CUITS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cargar primero el excel o csv\n",
    "archivo = None\n",
    "while True:\n",
    "    archivo = funciones.seleccionar_archivo()\n",
    "    print(archivo)\n",
    "    if archivo:\n",
    "        ruta_archivo = archivo.name\n",
    "        try:\n",
    "            cuit_tis = pd.read_excel(ruta_archivo)\n",
    "            #padron = pd.read_csv(archivo, sep=\";\", encoding=\"ISO-8859-1\")\n",
    "            print(cuit_tis)\n",
    "            break\n",
    "        except UnicodeDecodeError:\n",
    "            print(\"Error de decodificación de caracteres. Intenta con otra codificación o archivo.\")\n",
    "            continue\n",
    "    else:\n",
    "        print(\"Archivo incorrecto. Por favor, vuelva a cargarlo.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuit_tis[['CUITS','DNI']] = cuit_tis[['CUITS','DNI']].astype(int)\n",
    "cuit_tis.rename(columns={'CUITS':'CUIT_TIS','DNI':'DNI_TIS'}, inplace = True)\n",
    "\n",
    "cuit_tis.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CRUCE CUITS Y DNI DE TIS Y NUESTRSA LIQUIDACIONES "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liq_de_tis = pd.merge(cuit_tis, liq_convenio_final, left_on = \"DNI_TIS\", right_on=\"DNI_CONT\", how='left', indicator=True)\n",
    "liq_de_tis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liq_de_tis.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = filedialog.askdirectory()\n",
    "\n",
    "liq_de_tis.to_excel(save_path + '\\liquidacion_tis_final.xlsx', index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = filedialog.askdirectory()\n",
    "\n",
    "pago_tis.to_csv(save_path + 'tis_sd_epv.csv', sep=';', index=False, encoding='latin-1') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = filedialog.askdirectory()\n",
    "\n",
    "pago_tis.to_csv(save_path + 'historico.csv', sep=';', index=False, encoding='latin-1') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
